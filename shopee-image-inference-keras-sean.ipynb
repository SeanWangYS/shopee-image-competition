{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install -q tensorflow-addons==0.9.1\n!pip install -q image-classifiers==1.0.0\n!pip install -q efficientnet==1.1.0","execution_count":1,"outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: You are using pip version 20.2.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n\u001b[33mWARNING: You are using pip version 20.2.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n\u001b[33mWARNING: You are using pip version 20.2.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import math, re, os, glob, time, random\nfrom collections import namedtuple\nfrom functools import partial\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nfrom classification_models.tfkeras import Classifiers\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom kaggle_datasets import KaggleDatasets\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nprint(\"Tensorflow version \" + tf.__version__)\n\nK = tf.keras.backend\nL = tf.keras.layers\nAUTO = tf.data.experimental.AUTOTUNE","execution_count":2,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.1.0 and strictly below 2.3.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  UserWarning,\n","name":"stderr"},{"output_type":"stream","text":"Tensorflow version 2.3.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# TPU/GPU detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ndef get_strategy():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    else:\n        strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\n    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n    \n    return strategy\n\nstrategy = get_strategy()","execution_count":3,"outputs":[{"output_type":"stream","text":"Running on TPU  grpc://10.0.0.2:8470\nREPLICAS:  8\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Configuration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data setup\nSEED = 601\nGCS_PATH = KaggleDatasets().get_gcs_path('shopee-product-detection-open')  # used in tpu kernel\nGCS_PATH_2 = KaggleDatasets().get_gcs_path('sp-tfrecords-sz320')  # 'sp-tfrecords' or 'sp-tfrecords-sz320'\nDATA_PATH = '../input/shopee-product-detection-open/'\n\nMODEL_PATH = '../input/sp-rn50/'\nMODEL_PATH_2 = '../input/sp-rn50-cycs/'\nMODEL_PATH_3 = '../input/sp-rn50-folds/'\n\nMODEL_PATH_1_1 = '../input/sp-effnb4/'\nMODEL_PATH_1_2 = '../input/sp-effnb4-cycs/'\nMODEL_PATH_1_3 = '../input/sp-effnb4-folds/'\n\nMODEL_PATH_2_1 = '../input/sp-effnb5/'\nMODEL_PATH_2_2 = '../input/sp-effnb5-cycs/'\nMODEL_PATH_2_3 = '../input/sp-effnb5-folds/'\nMODEL_PATH_2_4 = '../input/sp-effnb5-folds-2/'\n\nCLASSES = sorted(os.listdir(DATA_PATH+'train/train/train'))\nIM_SZ = 320  # 224, 320, 384, 448, 512\nIMAGE_SIZE = [IM_SZ, IM_SZ]\nWHICH_FOLD = 0\n\n# training setup\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\nrandom.seed(SEED)\nnp.random.seed(SEED)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# numpy and matplotlib defaults\nnp.set_printoptions(threshold=15, linewidth=80)\n\ndef batch_to_numpy_images_and_labels(data, to_deprocess=False):\n    try:\n        images, labels = data\n        numpy_images = images.numpy()\n        numpy_labels = labels.numpy()\n    except:\n        images = data\n        numpy_images = images.numpy()\n        numpy_labels = None\n    # If no labels, only image IDs, return None for labels (this is the case for test data)\n    if to_deprocess:\n        numpy_images = np.stack([deprocessing(im) for im in numpy_images])\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_sample(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \ndef display_batch_of_images(databatch, predictions=None, to_deprocess=False):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch, to_deprocess)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n    else:\n        labels = np.argmax(labels, -1)\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_sample(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()\n\ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n\ndef display_training_curves(training, validation, title, subplot, figsize=(8,10)):\n    if subplot % 10 == 1:  # set up the subplots on the first call\n        plt.subplots(figsize=figsize)\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH + 'train.csv')\ntest_df = pd.read_csv(DATA_PATH + 'test.csv')\n\nNUM_TRAIN_IMAGES = train_df.shape[0]\nNUM_TEST_IMAGES = test_df.shape[0]\n\nprint('Num. of train images:', NUM_TRAIN_IMAGES)\nprint('Num. of test images:', NUM_TEST_IMAGES)","execution_count":6,"outputs":[{"output_type":"stream","text":"Num. of train images: 105390\nNum. of test images: 12186\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH_2 + '/train/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH_2 + '/test/*.tfrec')","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for caffe preproc mode\nMEAN_C = [123.68, 116.779, 103.939]\n\n# for torch preproc mode\nMEAN_T = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\n\ndef decode_image(image, mode='torch'):\n    assert mode in (None, 'tf', 'torch', 'caffe'), \"mode must be one of None, 'tf', 'torch', 'caffe'\"\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    if mode is None:\n        return image\n    if mode == 'tf':\n        image = image / 255.0  # convert image to floats in [0, 1] range\n    if mode == 'torch':\n        image = image / 255.0\n        image = (image - MEAN_T) / STD\n    if mode == 'caffe':\n        image = image - MEAN_C\n    return image\n\ndef deprocessing(image, mode='torch'):\n    assert mode in (None, 'tf', 'torch', 'caffe'), \"mode must be one of None, 'tf', 'torch', 'caffe'\"\n    def rescale(x):\n        low, high = x.min(), x.max()\n        x_rescaled = (x - low) / (high - low)\n        return x_rescaled\n    if mode is None or mode == 'tf':\n        return rescale(image)\n    if mode == 'torch':\n        return rescale(image * STD + MEAN_T)\n    if mode == 'caffe':\n        return rescale(image + MEAN_C)\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"label\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.one_hot(tf.cast(example['label'], tf.int32), len(CLASSES))\n    return image, label\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string means bytestring\n        \"filename\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    filename = example['filename']\n    return image, filename\n\ndef data_augment(image, label, p_hsv=0.6, p_affine=0.75, p_cutout=0.):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    r_hsv = tf.random.uniform([1], minval=0, maxval=1, dtype='float32', seed=SEED)\n    r_affine = tf.random.uniform([1], minval=0, maxval=1, dtype='float32', seed=SEED)\n    r_cutout = tf.random.uniform([1], minval=0, maxval=1, dtype='float32', seed=SEED)\n    \n    image = tf.image.random_flip_left_right(image)\n    if r_hsv < p_hsv:\n        image = tf.image.random_brightness(image, 0.15)\n        image = tf.image.random_saturation(image, 0.8, 2.3)\n        image = tf.image.random_contrast(image, 0.8, 1.3)\n    if r_affine < p_affine:\n        image = shift_scale_rotate(image, h_shift=0.1*IM_SZ, w_shift=0.1*IM_SZ)\n    if r_cutout < p_cutout:\n        image = cutout(image)\n    \n    return image, label\n\ndef get_training_dataset():\n    dataset = tf.data.TFRecordDataset(TRAIN_FILENAMES, num_parallel_reads=AUTO)\n    return (\n        dataset\n        .map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n        .repeat()\n        .shuffle(100000)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n\ndef get_validation_dataset():\n    dataset = tf.data.TFRecordDataset(VALID_FILENAMES, num_parallel_reads=AUTO)\n    return (\n        dataset\n        .map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n\ndef get_validation_dataset_tta():\n    dataset = tf.data.TFRecordDataset(VALID_FILENAMES, num_parallel_reads=AUTO)\n    return (\n        dataset\n        .map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n        .map(data_augment, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n\ndef get_test_dataset():\n    dataset = tf.data.TFRecordDataset(TEST_FILENAMES, num_parallel_reads=AUTO)\n    return (\n        dataset\n        .map(read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n    )\n\ndef get_test_dataset_tta():\n    dataset = tf.data.TFRecordDataset(TEST_FILENAMES, num_parallel_reads=AUTO)\n    return (\n        dataset\n        .map(read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n        .map(data_augment, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n    )\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform(image, matrix, border_mode=0):\n    BORDERS = ['constant', 'nearest']\n    border_mode = BORDERS[border_mode]\n    \n    DIM = IMAGE_SIZE[0]\n    C = DIM // 2\n    \n    # LIST DESTINATION PIXEL INDICES\n    y, x = tf.meshgrid(tf.range(DIM), tf.range(DIM))\n    x_c, y_c = tf.reshape(x - C, [-1]), tf.reshape(y - C, [-1])\n    x, y = tf.reshape(x, [-1]), tf.reshape(y, [-1])\n    if matrix.shape[0] == 2:\n        coord = tf.stack( [x_c,y_c] )   # (2, DIM*DIM)\n    else:\n        z = tf.ones([DIM*DIM], dtype='int32')\n        coord = tf.stack( [x_c,y_c,z] )   # (3, DIM*DIM)\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    coord_pr = tf.matmul(matrix, tf.cast(coord, dtype='float32'))\n    coord_pr = tf.cast(tf.round(coord_pr[:2,:] + C), dtype='int32')   # (2, DIM*DIM)\n    \n    # FIND ORIGIN PIXEL VALUES\n    if border_mode == 'constant':\n        x_pr, y_pr = coord_pr[0,:], coord_pr[1,:]\n        outside_ind = tf.logical_or( tf.logical_or(y_pr>DIM-1 , y_pr<0), tf.logical_or(x_pr>DIM-1 , x_pr<0))\n\n        x_pr = tf.boolean_mask(x_pr, tf.logical_not(outside_ind))   # (<DIM*DIM, )\n        y_pr = tf.boolean_mask(y_pr, tf.logical_not(outside_ind))   # (<DIM*DIM, )\n        x    = tf.boolean_mask(x, tf.logical_not(outside_ind))   # (<DIM*DIM, )\n        y    = tf.boolean_mask(y, tf.logical_not(outside_ind))   # (<DIM*DIM, )\n\n        coord_pr = tf.transpose( tf.stack( [x_pr, y_pr] ) )   # (<DIM*DIM, 2)\n        coord = tf.cast(tf.transpose( tf.stack( [x, y] ) ), 'int64')   # (<DIM*DIM, 2)\n\n        im_channels = tf.split(image, 3, axis=-1)\n        rot_channels = []\n        for im_val in im_channels:\n            rot_val = tf.squeeze(tf.gather_nd(im_val, coord_pr), axis=-1)   # (<DIM*DIM, )\n            rot = tf.SparseTensor(coord, rot_val, [DIM, DIM])\n            rot_channels.append(tf.sparse.to_dense(rot, default_value=0, validate_indices=False))\n\n        rot_image = tf.transpose(tf.stack(rot_channels), [1, 2, 0])   # (DIM, DIM, 3)\n    \n    if border_mode == 'nearest':\n        coord_pr = tf.clip_by_value(coord_pr, 0, DIM - 1)   # (2, DIM*DIM)\n        rot_image = tf.reshape( tf.gather_nd(image, tf.transpose(coord_pr)), [DIM, DIM, 3] )\n    \n    return rot_image\n\ndef rotate(image, angle):\n    angle = math.pi * angle / 180.\n    c1 = tf.math.cos(angle)\n    s1 = tf.math.sin(angle)\n    t_matrix = tf.reshape( tf.stack([c1,s1, -s1,c1]), [2,2] )\n    return transform(image, t_matrix)\n\ndef shear(image, angle):\n    angle = math.pi * angle / 180.\n    c1 = tf.math.cos(angle)\n    s1 = tf.math.sin(angle)\n    one = tf.constant([1], dtype='float32')\n    zero = tf.constant([0], dtype='float32')\n    t_matrix = tf.reshape( tf.stack([one[0],s1, zero[0],c1]), [2,2] )\n    return transform(image, t_matrix)\n\ndef zoom(image, height_zoom, width_zoom):\n    one = tf.constant([1], dtype='float32')\n    zero = tf.constant([0], dtype='float32')\n    t_matrix = tf.reshape( tf.stack([one[0]/height_zoom,zero[0], zero[0],one[0]/width_zoom]), [2,2] )\n    return transform(image, t_matrix)\n\ndef shift(image, height_shift, width_shift):\n    one = tf.constant([1], dtype='float32')\n    zero = tf.constant([0], dtype='float32')\n    t_matrix = tf.reshape( tf.stack([one[0],zero[0],height_shift, zero[0],one[0],width_shift, zero[0],zero[0],one[0]]), [3,3] )\n    return transform(image, t_matrix)\n\ndef shift_scale_rotate(image, rotation=15, shear=8, h_zoom=1, w_zoom=1, h_shift=20, w_shift=20):\n    rot = rotation * tf.random.normal([1], dtype='float32')\n    shr = shear * tf.random.normal([1], dtype='float32')\n    h_zoom = h_zoom + tf.random.normal([1], dtype='float32') / 10.\n    w_zoom = w_zoom + tf.random.normal([1], dtype='float32') / 10.\n    h_shift = h_shift * tf.random.normal([1], dtype='float32')\n    w_shift = w_shift * tf.random.normal([1], dtype='float32')\n    \n    angle = math.pi * rot / 180.\n    c1 = tf.math.cos(angle)\n    s1 = tf.math.sin(angle)\n    one = tf.constant([1], dtype='float32')\n    zero = tf.constant([0], dtype='float32')\n    rot_matrix = tf.reshape( tf.concat([c1,s1, -s1,c1], axis=0), [2,2] )\n    \n    angle = math.pi * shr / 180.\n    c1 = tf.math.cos(angle)\n    s1 = tf.math.sin(angle)\n    shr_matrix = tf.reshape( tf.concat([one,s1, zero,c1], axis=0), [2,2] )\n    \n    z_matrix = tf.reshape( tf.concat([one/h_zoom,zero, zero,one/w_zoom], axis=0), [2,2] )\n    \n    t_matrix = K.dot(K.dot(rot_matrix, shr_matrix), z_matrix)\n    t_image = transform(image, t_matrix)\n    \n    s_matrix = tf.reshape( tf.concat([one,zero,h_shift, zero,one,w_shift, zero,zero,one], axis=0), [3,3] )\n    return transform(t_image, s_matrix)\n\ndef cutout(image, min_height=0.4, min_width=0.4, max_height=0.6, max_width=0.6):\n    DIM = IMAGE_SIZE[0]\n    \n    cut_height = tf.cast(tf.round(tf.random.uniform([], minval=min_height*DIM, maxval=max_height*DIM)), 'int32')\n    cut_width = tf.cast(tf.round(tf.random.uniform([], minval=min_width*DIM, maxval=max_width*DIM)), 'int32')\n    x_min = tf.random.uniform([], minval=-cut_width//2, maxval=DIM-1-cut_width//2, dtype='int32')\n    x_max = x_min + cut_width\n    y_min = tf.random.uniform([], minval=-cut_height//2, maxval=DIM-1-cut_height//2, dtype='int32')\n    y_max = y_min + cut_height\n    if x_min < 0:\n        cut_width -= 0 - x_min\n        x_min = tf.clip_by_value(x_min, 0, x_max)\n    if y_min < 0:\n        cut_height -= 0 - y_min\n        y_min = tf.clip_by_value(y_min, 0, y_max)\n    if x_max > DIM:\n        cut_width -= x_max - DIM\n        x_max = tf.clip_by_value(x_max, x_min, DIM)\n    if y_max > DIM:\n        cut_height -= y_max - DIM\n        y_max = tf.clip_by_value(y_max, y_min, DIM)\n    \n    cut_area = tf.zeros([cut_height, cut_width, 3], dtype='float32')\n    pad_top = y_min\n    pad_bottom = DIM - y_max\n    pad_left = x_min\n    pad_right = DIM - x_max\n    cut_mask = tf.pad(cut_area, [[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n    \n    cut_image = tf.multiply(image, cut_mask)\n    return cut_image","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train/validation split"},{"metadata":{"trusted":true},"cell_type":"code","source":"VALID_FILENAMES = [TRAINING_FILENAMES[WHICH_FOLD]]\nTRAIN_FILENAMES = TRAINING_FILENAMES[:WHICH_FOLD] + TRAINING_FILENAMES[WHICH_FOLD+1:]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_TRAIN_IMAGES = count_data_items(TRAIN_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\nSTEPS_PER_EPOCH = math.ceil(NUM_TRAIN_IMAGES / BATCH_SIZE)\n# VALIDATION_STEPS = math.ceil(NUM_VALIDATION_IMAGES / BATCH_SIZE)\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAIN_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","execution_count":11,"outputs":[{"output_type":"stream","text":"Dataset: 100121 training images, 5269 validation images, 12186 unlabeled test images\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Dataset visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_dataset = get_validation_dataset()\n# val_dataset = val_dataset.unbatch().batch(5)\n# val_batch = iter(val_dataset)\n# images, labels = next(val_batch)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(5,5))\n# display_one_sample(images[1], '', (1,1,1));","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(5,5))\n# display_one_sample(shift_scale_rotate(images[1]), '', (1,1,1));","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(5,5))\n# display_one_sample(cutout(images[1]), '', (1,1,1));","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Peek at training data\n# train_dataset = get_training_dataset()\n# train_dataset = train_dataset.unbatch().batch(20)\n# train_batch = iter(train_dataset)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # run this cell again for next set of images\n# # longer because of the augmentation process\n# display_batch_of_images(next(train_batch), to_deprocess=True)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_dataset = get_validation_dataset()\n# val_dataset = val_dataset.unbatch().batch(20)\n# val_batch = iter(val_dataset)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # run this cell again for next set of images\n# display_batch_of_images(next(val_batch), to_deprocess=True)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # peer at test data\n# test_dataset = get_test_dataset()\n# test_dataset = test_dataset.unbatch().batch(20)\n# test_batch = iter(test_dataset)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # run this cell again for next set of images\n# display_batch_of_images(next(test_batch), to_deprocess=True)","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keras"},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConcatPooling2D(L.Layer):\n    \"Layer that concats `GlobalAveragePooling2D` and `GlobalMaxPooling2D`,\"\n    def __init__(self):\n        \"Output will be 2*output_size or 2 if output_size is None\"\n        super().__init__()\n        self.ap = L.GlobalAveragePooling2D()\n        self.mp = L.GlobalMaxPooling2D()\n    def call(self, x): return tf.concat([self.mp(x), self.ap(x)], 1)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"strategy = get_strategy()\n\nwith strategy.scope():\n    pretrained_model_1 = efn.EfficientNetB4(weights='noisy-student', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n    pretrained_model_2 = efn.EfficientNetB5(weights='noisy-student', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n#     resnet, _ = Classifiers.get('resnet50')\n#     pretrained_model = resnet(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n#     pretrained_model.trainable = True  # False = transfer learning, True = fine-tuning\n    \n    model_1 = tf.keras.Sequential([\n        pretrained_model_1,\n        L.GlobalAveragePooling2D(),\n        L.Dense(len(CLASSES), activation='softmax')\n    ])\n    \n    model_2 = tf.keras.Sequential([\n        pretrained_model_2,\n        L.GlobalAveragePooling2D(),\n        L.Dense(len(CLASSES), activation='softmax')\n    ])","execution_count":23,"outputs":[{"output_type":"stream","text":"Running on TPU  grpc://10.0.0.2:8470\nREPLICAS:  8\nDownloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_noisy-student_notop.h5\n71680000/71678424 [==============================] - 3s 0us/step\nDownloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b5_noisy-student_notop.h5\n115261440/115255328 [==============================] - 4s 0us/step\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def TTA(num_tta, model, beta=0.4, mode='test'):\n    assert mode in ('valid', 'test')\n    original_pred = 0\n    transformed_pred = 0\n    for i in range(num_tta):\n        if i == 0:\n            dataset = get_validation_dataset() if mode=='valid' else get_test_dataset()\n            images_ds = dataset.map(lambda image, _: image)\n            original_pred += model.predict(images_ds)\n        else:\n            dataset = get_validation_dataset_tta() if mode=='valid' else get_test_dataset_tta()\n            images_ds = dataset.map(lambda image, _: image)\n            transformed_pred += model.predict(images_ds) / (num_tta-1)\n\n    predictions = beta * original_pred + (1-beta) * transformed_pred\n    return predictions\n\nclass NNAverage(object):\n    def __init__(self, base_model, mu):\n        self.mu = mu\n        self.weight_copy = {}\n        for var in base_model.trainable_variables:\n            self.weight_copy[var.name] = 0\n\n    def update(self, model_shot):\n        for var in model_shot.trainable_variables:\n            self.weight_copy[var.name] += self.mu * var\n\n    def set_weights(self, avg_model):\n        for var in avg_model.trainable_variables:\n            var = self.weight_copy[var.name]\n\n@tf.function\ndef forward_model(data_iter):\n    def forward_step_fn(images, labels):\n        tmp = model(images, training=True)\n        \n    # this loop runs on the TPU\n    for _ in tf.range(STEPS_PER_EPOCH):\n        strategy.experimental_run_v2(forward_step_fn, next(data_iter))","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_dataset = get_validation_dataset()\n# images_ds = val_dataset.map(lambda image, label: image)\n# labels_ds = val_dataset.map(lambda image, label: label).unbatch()\n# valid_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\n# valid_labels = np.argmax(valid_labels, -1)\n# valid_labels","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# model.load_weights(MODEL_PATH + 'best_model.h5')\n# valid_preds = model.predict(images_ds)\n# valid_preds = np.argmax(valid_preds, axis=-1)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# # ensemble 4 snapshots from cyclic training\n\n# # model.load_weights(MODEL_PATH + 'best_model.h5')\n# # valid_preds = model.predict(images_ds)\n# for i in range(4):\n#     model.load_weights(MODEL_PATH_2 + f'best_model_{i}.h5')\n#     if i==0: valid_preds = model.predict(images_ds)\n#     else: valid_preds += model.predict(images_ds)\n# #     valid_preds += model.predict(images_ds)\n\n# valid_preds = np.argmax(valid_preds, axis=-1)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_acc = accuracy_score(valid_labels, valid_preds)\n# val_f1 = f1_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n# val_prec = precision_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n# val_rec = recall_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n\n# print('accuracy: {:.3f}, f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(val_acc, val_f1, val_prec, val_rec))","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TTA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# valid_preds = TTA(8, model, beta=0.3, mode='valid')\n# valid_preds = np.argmax(valid_preds, axis=-1)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# # ensemble 4 snapshots with TTA from cyclic training\n\n# # model.load_weights(MODEL_PATH + 'best_model.h5')\n# # valid_preds = TTA(8, model, beta=0.3, mode='valid')\n# for i in range(4):\n#     model.load_weights(MODEL_PATH_2 + f'best_model_{i}.h5')\n#     if i==0: valid_preds = TTA(8, model, beta=0.3, mode='valid')\n#     else: valid_preds += TTA(8, model, beta=0.3, mode='valid')\n# #     valid_preds += TTA(8, model, beta=0.3, mode='valid')\n\n# valid_preds = np.argmax(valid_preds, axis=-1)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_acc = accuracy_score(valid_labels, valid_preds)\n# val_f1 = f1_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n# val_prec = precision_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n# val_rec = recall_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n\n# print('accuracy: {:.3f}, f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(val_acc, val_f1, val_prec, val_rec))","execution_count":31,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SWA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# avg_obj = NNAverage(model, 1/4.)  # 1/5.\n\n# # model.load_weights(MODEL_PATH + 'best_model.h5')\n# # avg_obj.update(model)\n# for i in range(4):\n#     model.load_weights(MODEL_PATH_2 + f'best_model_{i}.h5')\n#     avg_obj.update(model)\n\n# avg_obj.set_weights(model)\n# train_dist_ds = strategy.experimental_distribute_dataset(get_training_dataset())\n# train_data_iter = iter(train_dist_ds)\n# forward_model(train_data_iter)\n\n# valid_preds = model.predict(images_ds)\n# valid_preds = np.argmax(valid_preds, axis=-1)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_acc = accuracy_score(valid_labels, valid_preds)\n# val_f1 = f1_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n# val_prec = precision_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n# val_rec = recall_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n\n# print('accuracy: {:.3f}, f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(val_acc, val_f1, val_prec, val_rec))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# valid_preds = TTA(8, model, beta=0.3, mode='valid')\n# valid_preds = np.argmax(valid_preds, axis=-1)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_acc = accuracy_score(valid_labels, valid_preds)\n# val_f1 = f1_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n# val_prec = precision_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n# val_rec = recall_score(valid_labels, valid_preds, labels=range(len(CLASSES)), average='macro')\n\n# print('accuracy: {:.3f}, f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(val_acc, val_f1, val_prec, val_rec))","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MODEL_PATH_1_1 = '../input/sp-effnb4/'\n# MODEL_PATH_1_2 = '../input/sp-effnb4-cycs/'\n# MODEL_PATH_1_3 = '../input/sp-effnb4-folds/'\n\n# MODEL_PATH_2_1 = '../input/sp-effnb5/'\n# MODEL_PATH_2_2 = '../input/sp-effnb5-cycs/'\n# MODEL_PATH_2_3 = '../input/sp-effnb5-folds/'\n# MODEL_PATH_2_4 = '../input/sp-effnb5-folds-2/'","execution_count":36,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = get_test_dataset()\ntest_images_ds = test_ds.map(lambda image, filename: image)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# print('Computing predictions...')\n# test_images_ds = test_ds.map(lambda image, filename: image)\n# probabilities = model.predict(test_images_ds)\n# # probabilities = TTA(8, model, beta=0.3)\n# predictions = np.argmax(probabilities, axis=-1)\n# predictions = [CLASSES[c] for c in predictions]","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# print('Computing predictions...')\n# # avg_obj = NNAverage(model, 1/4.)  # 1/5.\n\n# # model.load_weights(MODEL_PATH + 'best_model.h5')\n# # avg_obj.update(model)\n# # probabilities = model.predict(test_images_ds)\n# # probabilities = TTA(8, model, beta=0.3)\n# for i in range(4):\n#     model.load_weights(MODEL_PATH_2 + f'best_model_{i}.h5')\n# #     avg_obj.update(model)\n#     if i==0:\n# #         probabilities = model.predict(test_images_ds)\n#         probabilities = TTA(8, model, beta=0.3)\n#     else:\n# #         probabilities += model.predict(test_images_ds)\n#         probabilities += TTA(8, model, beta=0.3)\n# #     probabilities += model.predict(test_images_ds)\n# #     probabilities += TTA(8, model, beta=0.3)\n\n# # avg_obj.set_weights(model)\n# # train_dist_ds = strategy.experimental_distribute_dataset(get_training_dataset())\n# # train_data_iter = iter(train_dist_ds)\n# # forward_model(train_data_iter)\n# # probabilities += TTA(8, model, beta=0.3)\n\n# predictions = np.argmax(probabilities, axis=-1)\n# predictions = [CLASSES[c] for c in predictions]","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n\n# print('Computing predictions...')\n# # avg_obj = NNAverage(model, 1/6.)\n\n# model.load_weights(MODEL_PATH + 'best_model.h5')\n# # avg_obj.update(model)\n# probabilities = model.predict(test_images_ds)\n# # probabilities = TTA(8, model, beta=0.3)\n# for i in range(5):\n#     model.load_weights(MODEL_PATH_3 + f'best_model_{i}.h5')\n# #     avg_obj.update(model)\n#     probabilities += model.predict(test_images_ds)\n# #     probabilities = TTA(8, model, beta=0.3)\n\n# # avg_obj.set_weights(model)\n# # train_dist_ds = strategy.experimental_distribute_dataset(get_training_dataset())\n# # train_data_iter = iter(train_dist_ds)\n# # forward_model(train_data_iter)\n# # probabilities += TTA(8, model, beta=0.3)\n\n# predictions = np.argmax(probabilities, axis=-1)\n# predictions = [CLASSES[c] for c in predictions]","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_PATH_1_1 = '../input/speffnb4/'\nMODEL_PATH_1_2 = '../input/speffnb4cycs/'\nMODEL_PATH_1_3 = '../input/speffnb4folds/'\n\nMODEL_PATH_2_1 = '../input/speffnb5/'\nMODEL_PATH_2_2 = '../input/speffnb5cycs/'\nMODEL_PATH_2_3 = '../input/speffnb5folds/'\nMODEL_PATH_2_4 = '../input/speffnb5folds2/'","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nprint('Computing predictions...')\n\nmodel_1.load_weights(MODEL_PATH_1_1 + f'best_model.h5')\nprobabilities_cyc = model_1.predict(test_images_ds)\n# probabilities_cyc = TTA(8, model_1, beta=0.3)\nfor i in range(4):\n    model_1.load_weights(MODEL_PATH_1_2 + f'best_model_{i}.h5')\n    probabilities_cyc += model_1.predict(test_images_ds)\n#     probabilities_cyc += TTA(8, model_1, beta=0.3)\n\nmodel_2.load_weights(MODEL_PATH_2_1 + f'best_model.h5')\nprobabilities_cyc += model_2.predict(test_images_ds)\n# probabilities_cyc += TTA(8, model_2, beta=0.3)\nfor i in range(4):\n    model_2.load_weights(MODEL_PATH_2_2 + f'best_model_{i}.h5')\n    probabilities_cyc += model_2.predict(test_images_ds)\n#     probabilities_cyc += TTA(8, model_2, beta=0.3)\n\npredictions = np.argmax(probabilities_cyc, axis=-1)\npredictions = [CLASSES[c] for c in predictions]","execution_count":42,"outputs":[{"output_type":"stream","text":"Computing predictions...\nCPU times: user 1min 40s, sys: 31.8 s, total: 2min 12s\nWall time: 3min 9s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nprint('Computing predictions...')\n\nfor i in range(3):\n    model_1.load_weights(MODEL_PATH_1_3 + f'best_model_{i}.h5')\n    if i==0:\n        probabilities_cv = model_1.predict(test_images_ds)\n#         probabilities_cv = TTA(8, model_1, beta=0.3)\n    else:\n        probabilities_cv += model_1.predict(test_images_ds)\n#         probabilities_cv += TTA(8, model_1, beta=0.3)\n\nfor i in range(3):\n    model_2.load_weights(MODEL_PATH_2_3 + f'best_model_{i}.h5')\n    probabilities_cv += model_2.predict(test_images_ds)\n#     probabilities_cv += TTA(8, model_2, beta=0.3)\n\nfor i in range(3):\n    model_2.load_weights(MODEL_PATH_2_4 + f'best_model_{i}.h5')\n    probabilities_cv += model_2.predict(test_images_ds)\n#     probabilities_cv += TTA(8, model_2, beta=0.3)\n\npredictions = np.argmax(probabilities_cv, axis=-1)\npredictions = [CLASSES[c] for c in predictions]","execution_count":43,"outputs":[{"output_type":"stream","text":"Computing predictions...\nCPU times: user 1min 19s, sys: 28.4 s, total: 1min 47s\nWall time: 2min 9s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"probabilities = probabilities_cv + probabilities_cyc\n\npredictions = np.argmax(probabilities, axis=-1)\npredictions = [CLASSES[c] for c in predictions]","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Generating submission.csv file...')\ntest_fns_ds = test_ds.map(lambda image, filename: filename).unbatch()\ntest_fns = next(iter(test_fns_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\ntest_fns = [fn.split('/')[-1] for fn in test_fns]\n\nnp.savetxt('submission.csv', np.rec.fromarrays([test_fns, predictions]), fmt=['%s', '%s'], delimiter=',', header='filename,category', comments='')\n!head submission.csv","execution_count":45,"outputs":[{"output_type":"stream","text":"Generating submission.csv file...\nfilename,category\nfd663cf2b6e1d7b02938c6aaae0a32d2.jpg,20\n3e1b4fcb5f15a2b6eb9b188bec9ac98c.jpg,07\nc7fd77508a8c355eaab0d4e10efd6b15.jpg,27\n13f2954fa62bde63320bf1bd313964f8.jpg,32\n127f3e6d6e3491b2459812353f33a913.jpg,04\n6c6b59b94fcea916e1d49996611dabc7.jpg,38\n5ca4f2da11eda083064e6c36f37eeb81.jpg,22\nefbe090bdd5129de37da14901448566d.jpg,34\n46d681a542f2c71be017eef6aae23313.jpg,12\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}